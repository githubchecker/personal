# System-Design-Analysis

# System Design Roadmap Analysis

This document analyzes the System Design roadmap topics using the provided template structure.

## 1. System Design Introduction

### What is System Design?

- **What is it**: System design is the process of defining the architecture, components, modules, interfaces, and data for a system to satisfy specified requirements.
- **How it works**:
    - **Step 1: Requirements Gathering**: Define Functional (what it does) and Non-Functional (how it performs) requirements.
    - **Step 2: High-Level Design**: Draw the â€œBig Pictureâ€ (Load Balancer -> Web Server -> DB).
    - **Step 3: Deep Dive**: Zoom into complex components (e.g., â€œHow do we shard the DB?â€).
    - **Step 4: Trade-off Analysis**: Justify choices (e.g., â€œI chose Cassandra for write speed, accepting eventual consistencyâ€).
- **When to use it**: Building complex applications, distributed systems, or ensuring scalability/reliability.
- **Pros**: Clear roadmap, identifies bottlenecks early, facilitates communication.
- **Cons**: Time-consuming upfront, risk of over-engineering.
- **Sample Tools**: Draw.io, Lucidchart, C4 Model.
- **Interview Concepts**:
    - **Back-of-the-envelope Calculations**:
        - *What*: Rapidly estimating system capacity (e.g., â€œHow much storage for 1B users?â€).
        - *Why*: Proves you can check if a design is feasible before building it.
        - *Key Numbers*: Memorize powers of 2 (2â€„â‰ˆâ€„1*KB*, 2â€„â‰ˆâ€„1*GB*) and latencies (RAM = 100ns, Disk = 10ms).
            
            10
            
            30
            
    - **Trade-offs**:
        - *The Golden Rule*: There is no â€œperfectâ€ design. Every choice has a cost.
        - *Example*: â€œI chose SQL for ACID compliance, but I accept that scaling writes will be harder than NoSQL.â€

### Performance vs Scalability

### ğŸŸ¢ For Beginners (The Simple Explanation)

- **The Analogy**: Think of a **Car** on a **Highway**.
    - **Performance** is how fast the car can drive (e.g., 200 mph).
    - **Scalability** is how many cars the highway can handle at once.

### ğŸ”µ For Experts & Interviews (The Deep Dive)

- **1. What is it**:
    - **Performance**: Efficiency of a single unit of work.
    - **Scalability**: Capability to handle growing work by adding resources.
- **2. How it works (Mechanisms)**:
    - **Optimizing Performance**:
        - *Caching*: Reducing I/O by storing hot data in RAM (Redis).
        - *Concurrency*: Using non-blocking I/O (Event Loops) or Thread Pools to utilize CPU wait time.
        - *Algorithmic Efficiency*: Moving from *O*(*N*) to *O*(*N*logâ€†*N*).
            
            2
            
    - **Optimizing Scalability**:
        - *Vertical Scaling (Scale Up)*: Adding hardware (RAM/CPU) to a single node. Limited by hardware costs and physics.
        - *Horizontal Scaling (Scale Out)*: Partitioning data and logic across multiple nodes. Requires **Stateless** application servers and **Sharded** databases.
- **3. Interview Concepts**:
    - **Amdahlâ€™s Law**:
        - *Concept*: The theoretical limit of speedup is determined by the part of the task that *cannot* be parallelized.
        - *Takeaway*: If 10% of your code is sequential (locks, I/O), you can never speed up the system more than 10x, even with infinite CPUs.
    - **USL (Universal Scalability Law)**:
        - *Concept*: Extends Amdahlâ€™s law by adding â€œCoherence Penaltyâ€ (cost of nodes talking to each other).
        - *Takeaway*: At a certain point, adding more servers actually *slows down* the system due to communication overhead.

### Latency vs Throughput

### ğŸŸ¢ For Beginners (The Simple Explanation)

- **The Analogy**: **Coffee Shop**.
    - **Latency**: Wait time for one coffee.
    - **Throughput**: Coffees sold per hour.

### ğŸ”µ For Experts & Interviews (The Deep Dive)

- **1. What is it**:
    - **Latency**: Time from Request -> Response.
    - **Throughput**: Rate of successful requests (RPS).
- **2. The Relationship (Littleâ€™s Law)**:
    - *L*â€„=â€„*Î»W*. Capacity = Throughput Ã— Latency.
    - *Mechanism*: To increase Throughput without hurting Latency, you must increase **Parallelism** (add more workers/lanes).
- **4. Interview Concepts**:
    - **Head-of-Line (HOL) Blocking**:
        - *Concept*: When the first packet in a queue is stuck, *everything* behind it waits, even if they are ready.
        - *Example*: In HTTP/1.1, one slow request on a TCP connection blocks all other requests on that connection.
    - **Percentiles (p99 vs Average)**:
        - *Concept*: â€œAverageâ€ is misleading because it hides bad experiences.
        - *p99*: â€œ99% of requests are faster than Xâ€. This metric tracks the experience of your *slowest* users (often the most important ones with most data).
    - **Backpressure**:
        - *Concept*: A feedback mechanism where a slow consumer tells the fast producer to â€œslow downâ€.
        - *Without it*: The consumer crashes (OOM) or the queue overflows.

### Availability vs Consistency (CAP Theorem)

### ğŸŸ¢ For Beginners (The Simple Explanation)

- **The Analogy**: **Joint Bank Account**.
    - Network down between ATMs.
    - **CP**: ATM locks card (Error).
    - **AP**: ATM gives money (Risk of overdraft).

### ğŸ”µ For Experts & Interviews (The Deep Dive)

- **1. What is it**: You can only have 2 of 3: Consistency, Availability, Partition Tolerance.
- **2. How it works (Quorums)**:
    - To achieve **Strong Consistency** in a distributed system, you use a **Quorum**.
    - *R*â€…+â€…*W*â€„>â€„*N* (Read Nodes + Write Nodes > Total Nodes).
    - *Mechanism*: If you write to 3 nodes (*W*â€„=â€„3) and read from 3 nodes (*R*â€„=â€„3) in a 5-node cluster (*N*â€„=â€„5), you are guaranteed to see the latest data because the sets overlap.
- **3. Interview Concepts**:
    - **PACELC Theorem**:
        - *Concept*: An extension of CAP.
        - *Rule*: If Partition (**P**) -> Choose **A** or **C**.
        - *Else (No Partition)* -> Choose Latency (**L**) or Consistency (**C**).
        - *Why it matters*: Most of the time, the network is fine. You still have to choose between being fast (L) or being perfectly in sync (C).
    - **Split Brain**:
        - *Concept*: When a cluster loses connection, *both* sides might elect a Master.
        - *Result*: Both accept writes. When connection returns, data is corrupted/conflicting.
        - *Fix*: Quorums (need >50% votes to be Master).

## 2. Consistency Patterns

### Weak Consistency

### ğŸŸ¢ For Beginners

- **The Analogy**: **Live Video Chat**. Glitches are ignored.

### ğŸ”µ For Experts & Interviews

- **1. What is it**: No guarantee that reads see the latest write.
- **2. How it works (Fire and Forget)**:
    - The client sends data (often via **UDP**).
    - The server processes it if it arrives.
    - **No Acknowledgement (ACK)** is sent back. If packets are dropped, they are gone forever.
- **3. Use Cases**: VoIP, FPS Games (Player coordinates).
- **4. Interview Concepts**:
    - **Monotonic Reads**:
        - *Concept*: A guarantee that if a user sees a piece of data, they will never see an *older* version of that data later.
        - *Why it matters*: Without this, a user might refresh a page and see a comment â€œdisappearâ€ because they hit a stale replica.

### Eventual Consistency

### ğŸŸ¢ For Beginners

- **The Analogy**: **Social Media Likes**. Syncs over time.

### ğŸ”µ For Experts & Interviews

- **1. What is it**: Reads will *eventually* be correct if writes stop.
- **2. How it works (Convergence)**:
    - **Gossip Protocols**: Nodes periodically pick a random peer and exchange state information (Epidemic Algorithm).
    - **Read Repair**: When a client reads data, the system checks all replicas. If one is stale, it updates it in the background.
    - **Hinted Handoff**: If a node is down, the write is stored on a neighbor with a note (â€œHintâ€) to replay it when the node comes back.
- **3. Interview Concepts**:
    - **BASE Model**:
        - *Basically Available*: The system guarantees availability.
        - *Soft State*: The state of the system may change over time, even without input.
        - *Eventual Consistency*: The system will become consistent over time.
    - **Conflict Resolution**:
        - *LWW (Last Write Wins)*: Simple, uses timestamps. Danger: Clock skew can cause data loss.
        - *Vector Clocks*: Complex, detects *causality* (Event A happened before Event B). Allows smart merging.

### Strong Consistency

### ğŸŸ¢ For Beginners

- **The Analogy**: **Bank Transfer**. System locks until safe.

### ğŸ”µ For Experts & Interviews

- **1. What is it**: Immediate consistency for all readers.
- **2. How it works (Consensus)**:
    - **Two-Phase Commit (2PC)**:
        - *Phase 1 (Prepare)*: Coordinator asks all nodes â€œCan you commit?â€. Nodes lock the resource.
        - *Phase 2 (Commit)*: If all say â€œYesâ€, Coordinator says â€œCommitâ€. If one says â€œNoâ€, Coordinator says â€œAbortâ€.
    - **Raft/Paxos**: A leader is elected. The leader replicates the log to followers. Once a majority acknowledges, the write is committed.
- **3. Interview Concepts**:
    - **Linearizability vs Serializability**:
        - *Linearizability*: â€œReal-timeâ€ constraint. Once a write completes, all later reads see it. (Single object).
        - *Serializability*: â€œTransactionâ€ constraint. Transactions execute as if they were serial (one after another). (Multiple objects).
    - **2PC (Two-Phase Commit)**:
        - *Concept*: The â€œWedding Vowâ€ protocol.
        - *Phase 1*: â€œDo you take this transaction?â€ (Prepare).
        - *Phase 2*: â€œI doâ€ (Commit).
        - *Flaw*: It is **Blocking**. If the Coordinator dies, everyone waits forever.

## 3. Availability Patterns

### Fail-over

### ğŸŸ¢ For Beginners

- **The Analogy**: **Spare Tire vs.Â Dual Engines**.

### ğŸ”µ For Experts & Interviews

- **1. Active-Passive**:
    - **How it works (Heartbeats)**:
        - The Passive node sends a â€œPingâ€ every 1 second to the Active node.
        - If 3 Pings are missed, the Passive node assumes Active is dead.
        - **VIP Takeover**: The Passive node broadcasts an ARP update to claim the Virtual IP address, redirecting traffic to itself.
- **3. Interview Concepts**:
    - **VIP (Virtual IP)**:
        - *Concept*: An IP address that isnâ€™t tied to a specific physical machine. It â€œfloatsâ€ to whichever machine is currently the Master.
    - **Fencing (STONITH)**:
        - *Concept*: â€œShoot The Other Node In The Headâ€.
        - *Why*: If the old Master is merely â€œslowâ€ (not dead) and wakes up, it might try to write to the DB. Fencing kills it or cuts its storage access to prevent data corruption.
- **2. Active-Active**:
    - **How it works (Global Load Balancing)**:
        - DNS or Load Balancer distributes traffic to multiple active sites.
        - **State Sync**: Databases must be replicated bi-directionally (Master-Master), which is complex (Conflict Resolution needed).

### Replication

### ğŸŸ¢ For Beginners

- **The Analogy**: **Class Notes**.

### ğŸ”µ For Experts & Interviews

- **1. Master-Slave**:
    - **How it works (WAL Shipping)**:
        - The Master executes the write and appends it to its **Write Ahead Log (WAL)**.
        - The WAL entries are streamed to Slaves.
        - Slaves replay the WAL to update their own data state.
- **2. Master-Master**:
    - **How it works (Vector Clocks)**:
        - Each node maintains a â€œVector Clockâ€ `[NodeA: 1, NodeB: 2]`.
        - When syncing, if clocks conflict (concurrent writes), the system keeps *both* versions and asks the application/user to resolve the merge.
- **3. Interview Concepts**:
    - **Replication Lag**:
        - *Concept*: The time delay between a write on Master and its appearance on Slave.
        - *Consequence*: â€œRead Your Own Writeâ€ issues. User posts a comment, refreshes, and itâ€™s gone (because they read from a lagging slave).
    - **Quorums (*N*,â€†*R*,â€†*W*)**:
        - *Formula*: *R*â€…+â€…*W*â€„>â€„*N*.
        - *Meaning*: If you have 3 replicas (*N*â€„=â€„3), and you write to 2 (*W*â€„=â€„2), you MUST read from 2 (*R*â€„=â€„2) to guarantee you see the new data.
        - *Trade-off*: Higher *W* or *R* means lower availability (latency increases).

## 4. Core Components

### Domain Name System (DNS)

### ğŸŸ¢ For Beginners

- **The Analogy**: **The Phonebook**.
    - Computers donâ€™t know â€œGoogle.comâ€. They only know numbers (IP addresses like `142.250.190.46`).
    - DNS is the system that looks up the name â€œGoogle.comâ€ and gives your browser the number so it can call.

### ğŸ”µ For Experts & Interviews

- **1. How it works (Recursive vs Iterative)**:
    - **Step 1**: Browser checks **Local Cache**.
    - **Step 2**: OS checks **Hosts File** / **OS Cache**.
    - **Step 3**: Request sent to **ISP Resolver** (Recursive Resolver).
    - **Step 4**: ISP asks **Root Server (.)** -> Returns TLD Server IP.
    - **Step 5**: ISP asks **TLD Server (.com)** -> Returns Authoritative Server IP.
    - **Step 6**: ISP asks **Authoritative Server (google.com)** -> Returns `142.250.190.46`.
    - **Step 7**: ISP caches the result and returns it to the user.
- **2. Record Types**:
    - **A**: Name -> IPv4.
    - **AAAA**: Name -> IPv6.
    - **CNAME**: Name -> Name (Alias).
    - **MX**: Mail Exchange.
- **3. Interview Concepts**:
    - **TTL (Time To Live)**:
        - *Concept*: A timer attached to every DNS record.
        - *Trade-off*: High TTL = Fast lookups (cached), but slow updates (users see old IP if you change servers). Low TTL = Fast updates, but heavy load on DNS servers.
    - **Anycast Routing**:
        - *Concept*: Multiple servers share the *same* IP address.
        - *Mechanism*: BGP (Border Gateway Protocol) routes the user to the topologically nearest server. Used by CDNs and DNS (e.g., 8.8.8.8).

### Content Delivery Networks (CDN)

### ğŸŸ¢ For Beginners

- **The Analogy**: **Amazon Warehouses**.
    - If Amazon only had one warehouse in California, shipping to New York would take a week.
    - Instead, they put warehouses (CDNs) in every major city. When you order, the product comes from the warehouse *closest to you*.
    - *Result*: Faster delivery (Low Latency).

### ğŸ”µ For Experts & Interviews

- **1. How it works (Edge Caching)**:
    - **Request Routing**: User requests `image.jpg`. DNS resolves to the nearest CDN Edge Server (via Anycast).
    - **Cache Check**:
        - *Hit*: Edge returns file immediately.
        - *Miss*: Edge fetches file from **Origin Server**, saves a copy locally (with a TTL), and serves it.
- **2. Push vs.Â Pull**:
    - **Pull CDN**: The CDN fetches content only when a user asks for it. (Good for viral content).
    - **Push CDN**: You manually upload content to the CDN. (Good for large, stable files like software patches).
- **3. Interview Concepts**:
    - **Cache Invalidation**:
        - *The Hard Problem*: â€œThere are only two hard things in Computer Science: Cache Invalidation and naming things.â€
        - *Purge*: Forcing the CDN to delete a file (Slow, expensive).
        - *Versioning*: Changing the filename (`style.v2.css`). The CDN treats it as a new file (Fast, free, recommended).
    - **Dynamic Content (Edge Computing)**:
        - *Concept*: Running code (AWS Lambda@Edge, Cloudflare Workers) on the CDN server itself.
        - *Use Case*: A/B testing, Authentication, Custom Headers.

### Load Balancers

### ğŸŸ¢ For Beginners

- **The Analogy**: **The Receptionist**.
    - You walk into a busy office with 10 clerks. You donâ€™t know who is free.
    - The Receptionist (Load Balancer) sees who is not busy and points you to Clerk #3.
    - If Clerk #3 is sick (Server Down), the Receptionist sends you to Clerk #4.

### ğŸ”µ For Experts & Interviews

- **1. Layer 4 vs.Â Layer 7**:
    - **L4 (Transport Layer)**:
        - *Mechanism*: Inspects IP and Port. Modifies NAT table and forwards packet.
        - *Pros*: Extremely fast, handles millions of connections.
        - *Cons*: Dumb (canâ€™t see URL or Cookies).
    - **L7 (Application Layer)**:
        - *Mechanism*: Terminates the TCP connection, decrypts HTTPS, inspects the Request (URL, Headers), and creates a *new* connection to the backend.
        - *Pros*: Smart routing (`/video` -> VideoServer).
        - *Cons*: Slower (CPU intensive).
- **2. Algorithms**:
    - *Round Robin*: 1, 2, 3, 1, 2, 3â€¦
    - *Least Connections*: Send to the server with fewest active users.
    - *Consistent Hashing*: Maps the same user IP to the same server (Sticky Session).
- **3. Interview Concepts**:
    - **Health Checks**:
        - *Active*: The LB pings the server (`/health`) every 5s. If 200 OK, itâ€™s alive.
        - *Passive*: The LB watches real traffic. If users get 500 Errors, it marks the server as dead.
    - **SSL Termination**:
        - *Concept*: The LB handles the heavy CPU work of decrypting HTTPS.
        - *Benefit*: The backend servers only speak HTTP (lighter load), and you only manage certificates in one place (the LB).

## 5. Databases

### Relational DBMS (Scaling Strategies)

### ğŸŸ¢ For Beginners

- **The Analogy**: **The Library**.
    - **Single DB**: One librarian handles everything.
    - **Replication (Reading)**: You hire 5 assistants who can *only* read books to students. The main librarian focuses on writing new books.
    - **Sharding (Storage)**: You run out of shelf space. You buy a second building. Building A has books A-M. Building B has books N-Z.
    - **Federation (Function)**: You split the library into a â€œScience Libraryâ€ and an â€œArts Libraryâ€.

### ğŸ”µ For Experts & Interviews

- **1. Sharding (Horizontal Partitioning)**:
    - **How it works (Routing)**:
        - A **Routing Layer** (Smart Client or Proxy) sits between App and DB.
        - It looks at the query: `SELECT * FROM Users WHERE ID=105`.
        - It calculates `ShardKey = 105 % 10 = 5`.
        - It forwards the query *only* to Shard #5.
    - *The Problem*: **Cross-Shard Joins**. If you need data from Shard 1 and Shard 2, the application must query both and merge them (slow).
    - *The Fix*: **Denormalization**. Duplicate data so everything you need is on one shard.
- **2. Federation (Functional Partitioning)**:
    - Splitting DBs by domain (User DB, Order DB, Inventory DB).
    - *Trade-off*: No foreign keys across DBs. You lose ACID transactions spanning multiple domains (need 2PC or Sagas).
- **3. Interview Concepts**:
    - **Consistent Hashing**:
        - *Problem*: In normal hashing (`id % N`), adding a server changes `N`, remapping *all* keys.
        - *Solution*: Map servers and keys to a â€œRingâ€ (0-360 degrees). A key belongs to the next server on the ring. Adding a server only affects neighbors.
    - **Hot Partitions (Celebrity Problem)**:
        - *Scenario*: Justin Bieberâ€™s tweets are on Shard A. 100M people read them. Shard A melts.
        - *Fix*: Add a random suffix to the key (`Bieber_1`, `Bieber_2`) to spread the load across multiple shards.

### NoSQL: Key-Value Store

### ğŸŸ¢ For Beginners

- **The Analogy**: **The Coat Check**.
    - You give a ticket (Key: â€œ101â€). You get your coat (Value: â€œBlack Jacketâ€).
    - It is incredibly fast.
    - But you *cannot* ask: â€œGive me all black jacketsâ€. You can only ask for a specific ticket number.

### ğŸ”µ For Experts & Interviews

- **1. Internals**:
    - **Hash Table**: Data is stored in a massive in-memory hash map.
    - **Hash Ring**: In a distributed cluster, keys are distributed using Consistent Hashing to map keys to specific nodes.
    - *Performance*: *O*(1) read/write.
- **2. Use Cases**:
    - **Caching**: Storing HTML fragments or API responses (Redis).
    - **Sessions**: Storing user login state (DynamoDB).
    - **Shopping Carts**: Fast write/read by UserID.
- **3. Interview Concepts**:
    - **Eviction Policies**:
        - *LRU*: Remove the item that hasnâ€™t been used for the longest time.
        - *LFU*: Remove the item that is used least often.
    - **Persistence (Redis)**:
        - *RDB (Snapshot)*: Save the whole RAM to disk every X minutes. Fast restore, but data loss if crash happens between snapshots.
        - *AOF (Append Only File)*: Log every write command. Slower restore, but near-zero data loss.

### NoSQL: Document Store

### ğŸŸ¢ For Beginners

- **The Analogy**: **Filing Cabinet**.
    - In a normal DB (SQL), you must tear a page apart and store lines in different drawers (Normalization).
    - In a Document Store (MongoDB), you store the *entire page* (User + Address + Orders) in one folder.
    - *Benefit*: You get everything in one grab.

### ğŸ”µ For Experts & Interviews

- **1. Internals**:
    - **BSON (Binary JSON)**: Data is stored in a binary-encoded format that supports types (dates, integers) and is faster to parse than text JSON.
    - **Indexing**: B-Trees are used to index specific fields inside the JSON documents, allowing fast lookups like `db.users.find({ "address.city": "NY" })`.
- **2. Trade-offs**:
    - *Pros*: Flexible Schema (Schema-less). Great for rapid prototyping or data with varying attributes (Product Catalogs).
    - *Cons*: **No Joins**. You must do joins in the application code (slow) or duplicate data (denormalization).
- **3. Interview Concepts**:
    - **Denormalization**:
        - *Concept*: Intentionally duplicating data to avoid expensive Joins.
        - *Example*: Storing `UserName` and `UserAvatar` inside the `Comment` document.
        - *Trade-off*: If the user changes their Avatar, you must update it in 10,000 comments (Write Amplification).

### NoSQL: Wide Column Store

### ğŸŸ¢ For Beginners

- **The Analogy**: **A Multi-Dimensional Spreadsheet**.
    - Imagine a spreadsheet where every row can have *different* columns.
    - Row 1 has columns A, B, C. Row 2 has columns A, D, Z.
    - It is designed to hold Billions of rows and write to them incredibly fast.

### ğŸ”µ For Experts & Interviews

- **1. Internals (LSM Trees)**:
    - **Write Path**: Data is written to an in-memory **MemTable**.
    - **Flush**: When MemTable is full, it is sorted and flushed to disk as an **SSTable** (Sorted String Table). SSTables are immutable.
    - **Read Path**: System checks MemTable -> Then checks Bloom Filter -> Then checks SSTables on disk.
    - **Compaction**: Background process merges old SSTables to delete overwritten/deleted data.
- **2. Use Cases**:
    - Time-series data (IoT sensors, Stock prices), Chat History (Discord/Facebook Messages).
- **3. Interview Concepts**:
    - **Tunable Consistency**:
        - *Concept*: You can choose consistency level per query.
        - *Levels*: `ONE` (fastest), `QUORUM` (balanced), `ALL` (strongest, slowest).
    - **Bloom Filters**:
        - *Concept*: A probabilistic data structure that tells you if an element is â€œDefinitely Not In Setâ€ or â€œMaybe In Setâ€.
        - *Use*: Before checking disk (slow), check Bloom Filter (fast RAM). If it says â€œNoâ€, skip the disk read.

### NoSQL: Graph Database

### ğŸŸ¢ For Beginners

- **The Analogy**: **Connecting the Dots**.
    - SQL is bad at relationships (â€œWho are friends of friends of friends?â€). It requires complex joining.
    - Graph DB stores â€œUser A -> Friend -> User Bâ€ directly. Itâ€™s like walking a path.

### ğŸ”µ For Experts & Interviews

- **1. Internals**:
    - **Index-Free Adjacency**:
        - In SQL, finding a friend means scanning an Index (*O*(logâ€†*N*)).
        - In Graph DB, every node contains a direct physical RAM pointer to its neighbors.
        - *Result*: Traversing a relationship is *O*(1) (Pointer dereference).
- **2. Use Cases**:
    - Social Networks (Facebook Graph), Recommendation Engines (â€œPeople who bought X also bought Yâ€), Fraud Detection (Ring of thieves).
- **3. Interview Concepts**:
    - **Cypher/Gremlin**:
        - *Concept*: Declarative query languages designed for traversing relationships.
        - *Example*: `MATCH (u:User)-[:FRIEND]->(f:User) RETURN f`.
    - **Sharding Difficulty**:
        - *Problem*: Graphs are highly connected. Cutting a graph into pieces (partitioning) breaks many edges, requiring expensive cross-network traversals.
        - *Result*: Most Graph DBs scale vertically, not horizontally.

## 6. Caching

### Caching Strategies

### ğŸŸ¢ For Beginners

- **The Analogy**: **The Cheat Sheet**.
    - **Cache-Aside (Lazy Loading)**: You check your cheat sheet. If the answer isnâ€™t there, you look it up in the textbook and write it on the cheat sheet for next time.
    - **Write-Through**: When you learn a new fact, you write it in the textbook AND your cheat sheet at the same time.
    - **Write-Behind**: You write it on your cheat sheet first (fast). Later, when you have time, you copy it to the textbook.

### ğŸ”µ For Experts & Interviews

- **1. Cache-Aside (Lazy)**:
    - **How it works**:
        - Application checks Cache.
        - *Miss*: App queries DB -> App writes to Cache -> App returns result.
        - *Hit*: App returns result immediately.
    - *Pros*: Only caches what is requested (Cost efficient).
    - *Cons*: First request is slow (Cache Miss). Data can become stale if DB is updated directly.
- **2. Write-Through**:
    - **How it works**:
        - Application writes to Cache.
        - Cache *synchronously* writes to DB.
        - Write is confirmed only when both are done.
    - *Pros*: Strong consistency. Cache never has missing data.
    - *Cons*: Higher write latency (2 writes).
- **3. Write-Behind (Write-Back)**:
    - **How it works**:
        - Application writes to Cache. Cache immediately returns â€œSuccessâ€.
        - Cache *asynchronously* writes to DB (e.g., after 5 seconds or 100 writes).
    - *Pros*: Extremely fast writes.
    - *Cons*: **Data Loss Risk**. If Cache crashes before syncing to DB, data is gone.
- **4. Interview Concepts**:
    - **Thundering Herd (Cache Stampede)**:
        - *Scenario*: A popular cache key expires. 10,000 users request it simultaneously. All 10,000 get a â€œMissâ€ and hit the DB. DB crashes.
        - *Fix*: **Request Coalescing** (Singleflight). The first request goes to DB; the other 9,999 wait for the first one to finish and share the result.

### Eviction Policies

### ğŸŸ¢ For Beginners

- **The Analogy**: **The Closet**.
    - Your closet is full. You bought a new shirt. What do you throw out?
    - **LRU (Least Recently Used)**: Throw out the shirt you havenâ€™t worn in 3 years. (Smartest).
    - **FIFO (First In First Out)**: Throw out the oldest shirt you bought, even if you wear it every day. (Dumb).
    - **LFU (Least Frequently Used)**: Throw out the shirt you wore the least number of times.

### ğŸ”µ For Experts & Interviews

- **1. LRU (Least Recently Used)**:
    - **How it works**:
        - Uses a **Doubly Linked List** (for order) + **HashMap** (for lookup).
        - *Access*: Move item to the Head of the list (*O*(1)).
        - *Evict*: Remove item from the Tail of the list (*O*(1)).
    - *Use Case*: Social Media (Recent news is hot).
- **2. LFU (Least Frequently Used)**:
    - **How it works**:
        - Tracks a counter for every item.
        - Uses a Min-Heap or multiple lists to find the item with the lowest count.
    - *Use Case*: Analytics, Search Terms (Historical popularity matters).
- **3. Interview Concepts**:
    - **TTL (Time To Live)**:
        - *Concept*: Data expires after X seconds.
        - *Tip*: Add **Jitter** (randomness) to TTL. Instead of 60s, use 60s Â± 5s. This prevents all keys from expiring at the exact same second (which causes Thundering Herds).
    - **Random Replacement**:
        - *Concept*: Just delete a random key.
        - *Why*: It requires zero memory (no pointers/counters) and is surprisingly effective for uniform access patterns. Used in ARM CPU caches.

## 7. Asynchronism

### Message Queues

### ğŸŸ¢ For Beginners

- **The Analogy**: **The Voicemail**.
    - If you call a friend and they donâ€™t answer, you leave a voicemail.
    - They listen to it *later* when they are free.
    - You (Producer) donâ€™t have to wait on the line. They (Consumer) process it at their own speed.

### ğŸ”µ For Experts & Interviews

- **1. Models**:
    - **Point-to-Point (SQS)**: One message is consumed by exactly ONE worker.
    - **Pub/Sub (Kafka)**: One message is broadcast to MANY consumers (Topics).
- **2. How it works (Internals)**:
    - **Log-Based (Kafka)**: Messages are written to a disk log. Consumers track their own â€œOffsetâ€ (bookmark). Messages stay after reading (for retention period).
    - **Memory-Based (RabbitMQ)**: Messages are stored in RAM. Once a consumer Acks, the message is deleted.
- **3. Interview Concepts**:
    - **Dead Letter Queue (DLQ)**:
        - *Problem*: A â€œPoison Pillâ€ message (malformed JSON) crashes the worker. The worker restarts, reads the message again, and crashes again (Infinite Loop).
        - *Solution*: After X failed attempts, move the message to a separate â€œDead Letter Queueâ€ for human inspection.

### Task Queues

### ğŸŸ¢ For Beginners

- **The Analogy**: **The Restaurant Ticket Rail**.
    - Waiter (Web Server) takes an order and sticks the ticket on the rail.
    - Chefs (Workers) grab tickets one by one and cook.
    - The Waiter goes back to take more orders immediately.

### ğŸ”µ For Experts & Interviews

- **1. What is it**: A wrapper around a Message Queue specifically for executing code (jobs).
- **2. How it works**:
    - **Producer**: Adds a job payload (`{ "task": "email", "user": 1 }`) to Redis list.
    - **Worker**: Runs a loop. `BLPOP` (Blocking Pop) from Redis. Executes code.
    - **Result Backend**: Stores the return value (`"Success"`) in a DB for the user to check later.
- **3. Interview Concepts**:
    - **Idempotency**:
        - *Problem*: Task queues guarantee â€œAt-Least-Onceâ€ delivery. A job might run twice (e.g., worker crashes after charging card but before deleting job).
        - *Solution*: Make operations idempotent. `ChargeCard(orderID)` should check `if (order.isPaid) return`.
        - *Key*: â€œf(f(x)) = f(x)â€. Running it twice is safe.

### Back Pressure

### ğŸŸ¢ For Beginners

- **The Analogy**: **â€œI Love Lucyâ€ Chocolate Factory**.
    - The conveyor belt moves too fast. Lucy canâ€™t wrap the chocolates fast enough.
    - **Back Pressure**: Lucy yells â€œSTOP THE BELT!â€ (Flow Control).
    - **Without Back Pressure**: Chocolates pile up on the floor (System Crash / Out of Memory).

### ğŸ”µ For Experts & Interviews

- **1. Mechanisms**:
    - **TCP Window**: The receiver sends a window size (bytes it can accept) in every ACK packet. If window=0, sender stops.
    - **Token Bucket**: A rate limiter algorithm. You need a token to send a request. Tokens refill at a fixed rate.
- **2. Strategies**:
    - *Drop Head*: Delete the oldest message (Real-time video).
    - *Drop Tail*: Reject the new message (HTTP 503).
    - *Block*: Wait until space opens up (can cause cascading failure).
- **3. Interview Concepts**:
    - **Load Shedding**:
        - *Concept*: â€œBetter to serve 50% of users perfectly than 100% of users poorly.â€
        - *Action*: If CPU > 90%, immediately reject new requests with HTTP 503 (Service Unavailable) so existing requests can finish.

## 8. Communication Protocols

### REST (Representational State Transfer)

### ğŸŸ¢ For Beginners

- **The Analogy**: **The Web Browser**.
    - REST is just â€œHow the web worksâ€.
    - You ask for a page (GET). You submit a form (POST).
    - Itâ€™s simple, human-readable text (JSON), and works everywhere.

### ğŸ”µ For Experts & Interviews

- **1. Constraints**:
    - **Stateless**: Server stores no session context. Every request must have all info (Auth tokens). This allows any server to handle any request (Horizontal Scaling).
    - **Cacheable**: Responses must define if they can be cached.
    - **Uniform Interface**: Resources are identified by URLs (`/users/123`).
- **2. Richardson Maturity Model**:
    - *Level 0*: Swamp of POX (Plain Old XML).
    - *Level 1*: Resources.
    - *Level 2*: HTTP Verbs (GET/POST).
    - *Level 3*: **HATEOAS** (Hypermedia As The Engine Of Application State).
        - *Concept*: The API tells you what you can do next.
        - *Example*: Response includes `links: { "next_page": "/users?page=2", "delete_user": "/users/1" }`. Clients donâ€™t need to hardcode URLs.

### gRPC (Google Remote Procedure Call)

### ğŸŸ¢ For Beginners

- **The Analogy**: **The Walkie-Talkie**.
    - REST is like sending a letter (Text). Itâ€™s slow but easy to read.
    - gRPC is like a military radio (Binary). It sounds like static noise (unreadable to humans), but it is incredibly fast and compact.
    - Used when computers talk to other computers (Microservices), not when humans talk to computers.

### ğŸ”µ For Experts & Interviews

- **1. Internals**:
    - **Protocol Buffers (Protobuf)**:
        - Binary serialization.
        - Uses **Varints** (variable integers) to save space.
        - Strongly typed (`int32 id = 1`).
    - **HTTP/2**:
        - **Multiplexing**: Multiple requests over one TCP connection (No Head-of-Line blocking).
        - **Header Compression (HPACK)**: Reduces overhead.
- **2. Modes**:
    - *Unary*: 1 Request -> 1 Response.
    - *Streaming*: 1 Request -> Stream of Responses (or vice versa).
- **3. Interview Concepts**:
    - **Schema Evolution**:
        - *Problem*: You need to add a `phone_number` field, but old clients donâ€™t know about it.
        - *Protobuf Solution*: Fields have numbers (`int32 id = 1`). Old clients just ignore unknown field numbers. You never rename or renumber fields.

### GraphQL

### ğŸŸ¢ For Beginners

- **The Analogy**: **The Buffet**.
    - **REST (Menu)**: You order â€œBurgerâ€. You get Burger + Fries + Drink + Pickle. Even if you hate pickles. (Over-fetching).
    - **GraphQL (Buffet)**: You grab a plate. You take *exactly* what you want: â€œJust the Burger and the Drinkâ€. Nothing else.

### ğŸ”µ For Experts & Interviews

- **1. The Problem it Solves**:
    - **Over-fetching**: Getting too much data (wasting bandwidth).
    - **Under-fetching**: Getting too little data (needing 3 API calls to render one screen).
- **2. Internals**:
    - **Single Endpoint**: All requests go to `POST /graphql`.
    - **AST Parsing**: The server parses the query string into an Abstract Syntax Tree.
    - **Resolvers**: Functions that fetch the data for a specific field. The server walks the AST and calls resolvers.
- **3. Interview Concepts**:
    - **N+1 Problem**:
        - *Scenario*: You fetch a list of authors. Then for each author, you fetch their books.
        - *Fix*: **DataLoader**. It waits 1 tick of the event loop, collects all author IDs, and sends *one* batch query to the DB (`SELECT * FROM books WHERE author_id IN (...)`).

## 9. Performance Antipatterns

### Synchronous I/O

### ğŸŸ¢ For Beginners

- **The Analogy**: **The Phone Call vs.Â Texting**.
    - **Synchronous (Phone Call)**: You call the pizza place. You hold the line for 5 minutes until they answer. You canâ€™t do anything else while holding.
    - **Asynchronous (Texting)**: You text the pizza place. You put your phone down and play video games. When they reply, you look at it.
    - *Antipattern*: Making your web server â€œHold the lineâ€ (Block) for every database request. It runs out of lines (Threads) quickly.

### ğŸ”µ For Experts & Interviews

- **1. The Problem**:
    - Threads are expensive (Memory + Context Switching).
    - If you have 100 threads and 100 users make a slow DB request (2 sec), your server is dead for 2 seconds.
- **2. The Solution (How it works)**:
    - **Non-Blocking I/O (Event Loop)**:
        - Used by Node.js, Python Asyncio, Go Goroutines.
        - **Single Threaded Loop**: The main thread never waits. It fires a DB request and registers a **Callback**.
        - **OS Notification**: When the DB replies, the OS (via `epoll` or `kqueue`) notifies the Event Loop.
        - **Execution**: The Event Loop picks up the callback and executes it.
- **3. Interview Concepts**:
    - **Thread Starvation**:
        - *Scenario*: You have a thread pool of 100 threads. All 100 are waiting for a slow API.
        - *Result*: The 101st user gets rejected immediately, even if their request is simple (like â€œGet Health Statusâ€). The server appears dead even though CPU is 0% (itâ€™s just waiting).

### N+1 Extraneous Fetching

### ğŸŸ¢ For Beginners

- **The Analogy**: **The Grocery Trip**.
    - **Scenario**: You need to buy Eggs, Milk, and Bread.
    - **Efficient (1 Query)**: You drive to the store once and buy all 3 items.
    - **N+1 Problem**: You drive to the store for Eggs. Drive home. Drive back for Milk. Drive home. Drive back for Bread.
    - *Result*: You spent all your time driving (Network Latency).

### ğŸ”µ For Experts & Interviews

- **1. The Cause**:
    - Often caused by **ORMs** (Hibernate, Entity Framework, Django ORM).
    - **Code**: `users = db.get_users()` (1 Query). Loop: `for user in users: print(user.address)` (N Queries).
    - **SQL Generated**:
        - Query 1: `SELECT * FROM Users` (Returns 100 users).
        - Query 2â€¦101: `SELECT * FROM Address WHERE UserID = ?` (Executed 100 times).
- **2. The Fix**:
    - **Eager Loading**: `db.get_users().include('address')`.
    - **Batching**: Fetch all IDs, then `SELECT * FROM addresses WHERE user_id IN (1, 2, 3...)`.
- **3. Interview Concepts**:
    - **JOINs vs Subqueries**:
        - *Concept*: Understanding how the DB executes the query plan.
        - *N+1 vs JOIN*: N+1 is almost always slower because of network round-trips. A JOIN allows the DB engine to optimize the fetch in one go.

## 10. Cloud Design Patterns

### Circuit Breaker

### ğŸŸ¢ For Beginners

- **The Analogy**: **The Electrical Fuse**.
    - If you plug too many heaters into one outlet, the fuse blows. The power cuts off *instantly*.
    - Why? To stop the house from burning down.
    - In Software: If Service A calls Service B and Service B is dead, Service A stops calling it (Open Circuit) to save itself from waiting forever.

### ğŸ”µ For Experts & Interviews

- **1. States (How it works)**:
    - **Closed (Normal)**: Requests flow freely. The breaker counts errors.
    - **Open (Tripped)**: Error count > Threshold (e.g., 50% failure rate). All requests fail immediately (Fast Fail) without calling the backend.
    - **Half-Open (Testing)**: After a timeout (e.g., 10s), allow **1 request** to pass.
        - *Success*: Reset error count, go to **Closed**.
        - *Fail*: Go back to **Open**.
- **2. Interview Concepts**:
    - **Cascading Failure**:
        - *Scenario*: Service A calls Service B. Service B is slow. Service Aâ€™s threads fill up waiting for B. Service A dies. Service C (which calls A) now sees A is slow, fills up threads, and dies. The whole system collapses like dominos.
    - **Bulkhead Pattern**:
        - *Analogy*: A ship is divided into watertight compartments. If the hull is breached, only one section floods.
        - *Implementation*: Use separate thread pools for separate dependencies. If the â€œImage Serviceâ€ pool is exhausted, the â€œUser Serviceâ€ pool still works.

### CQRS (Command Query Responsibility Segregation)

### ğŸŸ¢ For Beginners

- **The Analogy**: **The Restaurant Kitchen**.
    - **Waiters (Read Model)**: They have menus. They answer â€œWhat is the price of soup?â€. They donâ€™t cook.
    - **Chefs (Write Model)**: They cook. They donâ€™t talk to customers.
    - *Benefit*: You can hire 50 waiters and only 5 chefs because reading the menu is easier than cooking.

### ğŸ”µ For Experts & Interviews

- **1. The Separation**:
    - **Command (Write)**: `CreateOrder()`. Enforces business rules. High consistency. Normalized DB (3NF).
    - **Query (Read)**: `GetOrders()`. Optimized for reading. Denormalized DB (No Joins).
- **2. How it works (Synchronization)**:
    - When a Command writes to the Write DB, it publishes an **Event** (`OrderCreated`).
    - A background worker consumes the event and updates the Read DB.
    - *Result*: **Eventual Consistency**.
- **3. Interview Concepts**:
    - **Materialized Views**:
        - *Concept*: A database table that contains the *results* of a query.
        - *Why*: Running a complex JOIN on 10M rows takes 5 seconds. Reading a pre-calculated Materialized View takes 5ms.
        - *Cost*: You must update the view whenever the underlying data changes (Eventual Consistency).

### Event Sourcing

### ğŸŸ¢ For Beginners

- **The Analogy**: **The Bank Statement**.
    - A Bank doesnâ€™t just store â€œBalance: $100â€.
    - It stores: â€œDeposit $50â€, â€œWithdraw $20â€, â€œDeposit $70â€.
    - To get the balance, you replay the history.
    - *Benefit*: You can see exactly *how* you got to $100.

### ğŸ”µ For Experts & Interviews

- **1. How it works**:
    - **Event Store**: The â€œSource of Truthâ€ is an append-only log of immutable events (`OrderCreated`, `ItemAdded`).
    - **Replay**: Current state is derived by replaying events from the beginning (Fold/Reduce function).
    - **Snapshots**: To avoid replaying 1 million events, save the state at event #999,000 and replay only from there.
- **2. Pros/Cons**:
    - *Pros*: Audit trail, Time Travel (debug exactly what happened at 2:00 PM).
    - *Cons*: Complexity, Storage growth.
- **3. Interview Concepts**:
    - **Saga Pattern**:
        - *Problem*: Distributed Transactions (spanning multiple microservices) are hard. 2PC is too slow.
        - *Solution*: A sequence of local transactions. Service A does X. If successful, trigger Service B.
        - *Compensation*: If Service B fails, trigger a â€œUndoâ€ transaction in Service A (e.g., Refund the money).

### Strangler Fig

### ğŸŸ¢ For Beginners

- **The Analogy**: **The Tree Vine**.
    - A Strangler Fig tree grows around an old tree. Eventually, the old tree dies and rots away, leaving only the new tree standing.
    - **In Software**: You donâ€™t rewrite a massive old app (Monolith) all at once. You build *one* new feature next to it. Then another. Eventually, the old app is empty and you delete it.

### ğŸ”µ For Experts & Interviews

- **1. How it works (Traffic Splitting)**:
    - Place an **API Gateway** in front of the Legacy Monolith.
    - **Rule 1**: If URL starts with `/api/v2/cart`, route to **New Microservice**.
    - **Rule 2**: Else, route to **Legacy Monolith**.
    - Over time, add more rules until Rule 2 is never hit.
- **2. Interview Concepts**:
    - **Anti-Corruption Layer (ACL)**:
        - *Problem*: The Legacy system has a terrible database schema (e.g., column names like `col_x_99`).
        - *Solution*: Donâ€™t let that garbage leak into your new Microservice. Build a small adapter layer that translates `col_x_99` to `User.email` before it enters your clean system.

### Sharding (Database)

### ğŸŸ¢ For Beginners

- **The Analogy**: **The Encyclopedia Set**.
    - One book is too heavy to hold all knowledge (A-Z).
    - So you split it into volumes: Vol 1 (A-C), Vol 2 (D-F), etc.
    - If you need to look up â€œCatâ€, you pick Vol 1. You donâ€™t need to touch Vol 2.

### ğŸ”µ For Experts & Interviews

- **1. Strategies**:
    - **Range Based**: `User_ID 1-1000` -> Shard A. (Problem: Uneven distribution if IDs are sequential).
    - **Hash Based**: `hash(User_ID) % 10` -> Shard B. (Good distribution).
    - **Geo Based**: US Users -> US Shard.
- **2. How it works (Virtual Nodes)**:
    - To solve the **Resharding Nightmare**, use **Consistent Hashing**.
    - Instead of mapping physical nodes to the ring, map 1000 â€œVirtual Nodesâ€ per physical node.
    - When adding a physical server, you just move some Virtual Nodes to it, minimizing data transfer.
- **3. Interview Concepts**:
    - **Consistent Hashing**:
        - *Refresher*: Essential for sharding to minimize data movement.
        - *Virtual Nodes*: To ensure even distribution, each physical server appears as 100 â€œVirtual Nodesâ€ scattered around the ring. This prevents one lucky server from getting a huge chunk of data just by chance.

### Publisher-Subscriber (Pub/Sub)

### ğŸŸ¢ For Beginners

- **The Analogy**: **The Newspaper**.
    - The Journalist (Publisher) writes a story. They donâ€™t know who will read it.
    - They send it to the Newspaper (Topic).
    - You (Subscriber) subscribe to the Newspaper. You get the story.
    - The Journalist doesnâ€™t need to know your address.

### ğŸ”µ For Experts & Interviews

- **1. Decoupling**:
    - Producers and Consumers donâ€™t know about each other. They only know the **Topic**.
- **2. How it works (Offset Tracking)**:
    - **Topic**: A logical channel (e.g., â€œUserSignupsâ€).
    - **Partitions**: A topic is split into partitions for scalability.
    - **Consumer Group**: A group of workers. Kafka ensures that each partition is consumed by *only one* worker in the group (Parallelism).
    - **Offset**: The consumer commits its progress (â€œI have read up to message #50â€). If it crashes, it restarts from #51.
- **3. Interview Concepts**:
    - **Consumer Groups (Kafka)**:
        - *Concept*: A way to parallelize processing.
        - *Mechanism*: If a Topic has 10 Partitions, you can have a â€œGroupâ€ of 10 consumers. Each consumer reads from exactly 1 partition.
        - *Benefit*: You process messages 10x faster than a single consumer.